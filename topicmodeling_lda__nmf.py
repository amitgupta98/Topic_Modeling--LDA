# -*- coding: utf-8 -*-
"""TopicModeling_LDA__NMF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ghvjBzUeIuf2KBcfzrJn624tYf0StRBr
"""

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

# Preprocessing on npr dataset 
# www.npr.org
import pandas as pd
npr = pd.read_csv('npr (4).csv')
npr.head()

len(npr)
print(npr.shape)

npr['Article'][1]

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')
dtm = cv.fit_transform(npr['Article'])
dtm

#from sklearn.decomposition import LatentDirichletAllocation
#LDA = LatentDirichletAllocation(n_components=7,random_state=42)
from sklearn.decomposition import NMF
LDA = NMF(n_components=7,random_state=42)
LDA.fit(dtm)

"""# Three Steps Away...
### Grab the vocab.
### Grab the topic
### and finally grab the highest prob. word per topic
"""

len(cv.get_feature_names())

type(cv.get_feature_names())

cv.get_feature_names()[5510]

import random

for i in range(10):
    random_word_id = random.randint(0,54776)
    print(cv.get_feature_names()[random_word_id])

"""### Showing Top Words Per Topic"""

len(LDA.components_)

LDA.components_.shape

LDA.components_

len(LDA.components_[0])

single_topic = LDA.components_[0]

# Returns the indices that would sort this array.
single_topic.argsort()

#lets understand the argsort in simple example
import numpy as np
arr = np.array([10,200,1])
arr.argsort()

# Word least representative of this topic
single_topic[18302]

# Word most representative of this topic
single_topic[42997]

# Top 10 words for this topic:
single_topic.argsort()[-10:]

top_word_indices = single_topic.argsort()[-10:]

for index in top_word_indices:
    print(cv.get_feature_names()[index])

"""These look like business articles perhaps... Let's confirm by using .transform() on our vectorized articles to attach a label number. But first, let's view all the 10 topics found."""

for index,topic in enumerate(LDA.components_):
    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')
    print([cv.get_feature_names()[i] for i in topic.argsort()[-15:]])
    print('\n')

"""### Attaching Discovered Topic Labels to Original Articles"""

dtm

dtm.shape

len(npr)

topic_results = LDA.transform(dtm)

topic_results.shape

topic_results[0]

topic_results[0].round(2)

topic_results[0].argmax()

"""This means that our model thinks that the first article belongs to topic #1.

### Combining with Original Data
"""

npr.head()

topic_results.argmax(axis=1)

npr['Topic'] = topic_results.argmax(axis=1)

npr.head(20)

"""##NON NEGATIVE MATRIX FACTORIZATION ALGORITHMS"""

#https://scikit-learn.org/stable/modules/decomposition.html#nmf

import numpy as np
from sklearn.decomposition import NMF
X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])

model = NMF(n_components=2, init='random', random_state=0)

W = model.fit_transform(X)
H = model.components_

X_new = np.array([[1, 0], [1, 6.1], [1, 0], [1, 4], [3.2, 1], [0, 4]])
W_new = model.transform(X_new)

W

H

X_new

W_new

"""Using scikit-learn. We use the built-in 20 newsgroups dataset and see what topics are generated."""

#https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html
import numpy as np
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF

data= fetch_20newsgroups(remove=('headers', 'footers', 'quotes')).data

# convert the text to a tf-idf weighted term-document matrix
 
vectorizer = TfidfVectorizer(max_features=2000, min_df=10, stop_words='english')
X = vectorizer.fit_transform(data)
idx_to_word = np.array(vectorizer.get_feature_names())
 
# apply NMF
 
nmf = NMF(n_components=20, solver="mu")
W = nmf.fit_transform(X)
H = nmf.components_
 
# print the topics
 
for i, topic in enumerate(H):
    print("Topic {}: {}".format(i + 1, ",".join([str(x) for x in idx_to_word[topic.argsort()[-10:]]])))

